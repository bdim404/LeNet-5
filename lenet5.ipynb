{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet å­¦ä¹ ç¬”è®°\n",
    "\n",
    "## ç¯å¢ƒ\n",
    "æˆ‘ä½¿ç”¨çš„è®¾å¤‡ç¯å¢ƒï¼š\n",
    "```\n",
    "                    c.'          bdim404@BdimMacBook-Pro.local \n",
    "                 ,xNMM.          ----------------------------- \n",
    "               .OMMMMo           OS: macOS 14.5 23F79 arm64 \n",
    "               lMM\"              Host: MacBookPro18,4 \n",
    "     .;loddo:.  .olloddol;.      Kernel: 23.5.0 \n",
    "   cKMMMMMMMMMMNWMMMMMMMMMM0:    Uptime: 14 days, 31 mins \n",
    " .KMMMMMMMMMMMMMMMMMMMMMMMWd.    Packages: 293 (nix-user) \n",
    " XMMMMMMMMMMMMMMMMMMMMMMMX.      Shell: bash 5.2.26 \n",
    ";MMMMMMMMMMMMMMMMMMMMMMMM:       Resolution: 3024x1964 \n",
    ":MMMMMMMMMMMMMMMMMMMMMMMM:       DE: Aqua \n",
    ".MMMMMMMMMMMMMMMMMMMMMMMMX.      WM: Quartz Compositor \n",
    " kMMMMMMMMMMMMMMMMMMMMMMMMWd.    WM Theme: Blue (Dark) \n",
    " 'XMMMMMMMMMMMMMMMMMMMMMMMMMMk   Terminal: Apple_Terminal \n",
    "  'XMMMMMMMMMMMMMMMMMMMMMMMMK.   Terminal Font: Monaco \n",
    "    kMMMMMMMMMMMMMMMMMMMMMMd     CPU: Apple M1 Max \n",
    "     ;KMMMMMMMWXXWMMMMMMMk.      GPU: Apple M1 Max \n",
    "       \"cooc*\"    \"*coo'\"        Memory: 29725MiB / 65536MiB \n",
    "\n",
    "```\n",
    "æˆ‘ä½¿ç”¨çš„ python ç‰ˆæœ¬æ˜¯ 3.11.0 å¹¶ä¸”æ˜¯é€šè¿‡ nix å®‰è£…çš„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‚è€ƒ pytorch å®˜ç½‘çš„é“¾æ¥è¿›è¡Œå®‰è£… [Installing on macOS](https://pytorch.org/get-started/locally/)\n",
    "pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./lenet5venv/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in ./lenet5venv/lib/python3.11/site-packages (0.18.1)\n",
      "Requirement already satisfied: torchaudio in ./lenet5venv/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in ./lenet5venv/lib/python3.11/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./lenet5venv/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./lenet5venv/lib/python3.11/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in ./lenet5venv/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./lenet5venv/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./lenet5venv/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in ./lenet5venv/lib/python3.11/site-packages (from torchvision) (2.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./lenet5venv/lib/python3.11/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./lenet5venv/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./lenet5venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# å®šä¹‰æ‰¹é‡å¤§å°ä¸º64ï¼Œè¿™æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¯æ¬¡ä¼ é€’ç»™ç¥ç»ç½‘ç»œçš„æ ·æœ¬æ•°é‡\n",
    "batch_size = 64\n",
    "\n",
    "# æ•°å­—çš„ç§ç±»æ•°é‡ä¸º10\n",
    "num_classes = 10\n",
    "\n",
    "# å®šä¹‰å­¦ä¹ ç‡ä¸º0.001 \n",
    "learning_rate = 0.001\n",
    "\n",
    "# å®šä¹‰è®­ç»ƒè½®æ•°ä¸º10ï¼Œè¿™æ„å‘³ç€æ•´ä¸ªæ•°æ®é›†å°†è¢«ä¼ é€’ç»™ç¥ç»ç½‘ç»œ10æ¬¡\n",
    "num_epochs = 10\n",
    "\n",
    "# å®šä¹‰äº†å°†åœ¨ Apple è®¾å¤‡ä½¿ç”¨ GPU è¿›è¡Œè®­ç»ƒ\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½ MNIST æ•°æ®é›†\n",
    "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                           train = True, # 'è¡¨ç¤ºæˆ‘ä»¬éœ€è¦åŠ è½½è®­ç»ƒæ•°æ®é›†\n",
    "                                           transform = transforms.Compose([ # transform çš„ä½œç”¨æ˜¯å®šä¹‰äº†å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†çš„æ–¹å¼\n",
    "                                                  transforms.Resize((32,32)), # å°†å›¾åƒå¤§å°è°ƒæ•´ä¸º32x32åƒç´ ã€‚åŸå§‹MNISTå›¾åƒæ˜¯28x28åƒç´ ï¼Œè¿™é‡Œæˆ‘ä»¬å°†å…¶å¢åŠ åˆ°ä¸CIFAR-10æ•°æ®é›†ç›¸åŒçš„å°ºå¯¸ä»¥æ–¹ä¾¿åç»­å¤„ç†\n",
    "                                                  transforms.ToTensor(), # å°†å›¾åƒè½¬æ¢ä¸ºPyTorch Tensoræ ¼å¼ï¼Œå¹¶å°†åƒç´ å€¼ç¼©æ”¾åˆ°[0, 1]ä¹‹é—´\n",
    "                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]), # æ ‡å‡†åŒ–å›¾åƒæ•°æ®ã€‚è¿™é‡Œä½¿ç”¨äº†MNISTè®­ç»ƒå’Œæµ‹è¯•é›†çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä»¥ç¡®ä¿æ•°æ®åœ¨ä¸åŒçš„æ‰¹æ¬¡ä¸­æœ‰ç›¸ä¼¼çš„åˆ†å¸ƒã€‚\n",
    "                                           download = True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                          train = False,\n",
    "                                          transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
    "                                          download=True)\n",
    "\n",
    "# åˆ›å»ºäº†ä¸€ä¸ªPyTorch DataLoaderå¯¹è±¡ï¼Œå®ƒæä¾›äº†ä»è®­ç»ƒæ•°æ®é›†ä¸­æŒ‰æ‰¹åŠ è½½å’Œè¿­ä»£æ•°æ®çš„åŠŸèƒ½ã€‚\n",
    "# 'batch_size'å‚æ•°æŒ‡å®šæ¯ä¸ªæ‰¹æ¬¡åŒ…å«å¤šå°‘æ ·æœ¬ï¼Œ'shuffle=True'è¡¨ç¤ºåœ¨æ¯ä¸ªæ—¶æœŸç»“æŸæ—¶é‡æ–°æ’åˆ—æ•°æ®ä»¥å¢åŠ éšæœºæ€§ã€‚\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬æ›´æ·±å…¥åœ°è®¨è®ºNormalizeæ“ä½œã€‚\n",
    "\n",
    "MNISTæ•°æ®é›†æ˜¯ç°åº¦å›¾åƒæ•°æ®ï¼Œå…¶åƒç´ å€¼èŒƒå›´ä»0ï¼ˆé»‘è‰²ï¼‰åˆ°255ï¼ˆç™½è‰²ï¼‰ã€‚é€šå¸¸åœ¨è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ï¼Œå°†è¾“å…¥ç‰¹å¾æ ‡å‡†åŒ–åˆ°å‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º1çš„åˆ†å¸ƒä¸­ä¼šæœ‰ç›Šå¤„ã€‚è¿™æ ·å¯ä»¥ä½¿å¾—æ¨¡å‹æ›´å®¹æ˜“åœ°å­¦ä¹ å¹¶æ”¶æ•›ã€‚\n",
    "\n",
    "`transforms.Normalize(mean = (...), std = (...))`æ˜¯PyTorchæä¾›çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºæ ‡å‡†åŒ–è¾“å…¥æ•°æ®ã€‚å®ƒæ¥å—ä¸¤ä¸ªå‚æ•°ï¼šå‡å€¼å’Œæ ‡å‡†å·®ã€‚åœ¨è¿™æ®µä»£ç ä¸­ï¼Œæˆ‘ä»¬ä¼ é€’äº†MNISTè®­ç»ƒé›†çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆåˆ†åˆ«ä¸º0.1307å’Œ0.3081ï¼‰ã€‚\n",
    "\n",
    "å‡å€¼å’Œæ ‡å‡†å·®é€šå¸¸æ˜¯æ ¹æ®è®­ç»ƒæ•°æ®é›†è®¡ç®—å¾—å‡ºçš„ç»Ÿè®¡é‡ã€‚åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œæä¾›äº†MNISTè®­ç»ƒé›†çš„å‡å€¼ï¼ˆ0.1307ï¼‰å’Œæ ‡å‡†å·®ï¼ˆ0.3081ï¼‰ã€‚\n",
    "\n",
    "è¿™äº›å€¼ç”¨äºæ ‡å‡†åŒ–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ï¼Œä»¥ä½¿å®ƒä»¬å…·æœ‰ç›¸ä¼¼çš„åˆ†å¸ƒã€‚åœ¨å®è·µä¸­ï¼Œè®¡ç®—è¿™äº›å€¼é€šå¸¸æ˜¯åœ¨åŠ è½½æ•°æ®ä¹‹å‰å®Œæˆçš„ï¼Œå› ä¸ºæˆ‘ä»¬å¸Œæœ›ç¡®ä¿æµ‹è¯•æ•°æ®é›†ä¸è®­ç»ƒæ•°æ®é›†å…·æœ‰ç›¸åŒçš„ç»Ÿè®¡å±æ€§ï¼ˆå³ï¼Œå‡å€¼å’Œæ ‡å‡†å·®ï¼‰ã€‚\n",
    "\n",
    "è®¡ç®—è¿™äº›å€¼æ—¶ï¼Œä¸€èˆ¬ä¼šå°†æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„åƒç´ å€¼ç»„åˆæˆä¸€ä¸ªå‘é‡ï¼Œå¹¶å¯¹å…¶è¿›è¡Œå¦‚ä¸‹è®¡ç®—ï¼š\n",
    "\n",
    "- å‡å€¼ï¼š`mean = sum(pixels) / num_pixels`\n",
    "- æ ‡å‡†å·®ï¼š`std = sqrt(sum((pixel - mean)^2) / num_pixels)`\n",
    "\n",
    "è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†åœ¨ä¸åŒæ‰¹æ¬¡ä¸­å…·æœ‰ç›¸ä¼¼çš„åˆ†å¸ƒã€‚ä½¿ç”¨æ­£ç¡®è®¡ç®—çš„å‡å€¼å’Œæ ‡å‡†å·®å¯¹è¾“å…¥è¿›è¡Œæ ‡å‡†åŒ–æ˜¯ç¥ç»ç½‘ç»œè®­ç»ƒçš„ä¸€ç§å¸¸è§æŠ€æœ¯ï¼Œå®ƒæœ‰åŠ©äºæ¨¡å‹æ›´å¿«åœ°æ”¶æ•›å¹¶è·å¾—è¾ƒå¥½çš„æ€§èƒ½ã€‚\n",
    "\n",
    "Normalizeæ“ä½œå¯¹å›¾åƒæ•°æ®è¿›è¡Œä»¥ä¸‹è½¬æ¢ï¼š\n",
    "\n",
    "`normalized_image = (image - mean) / std`\n",
    "\n",
    "å…¶ä¸­ï¼Œ'image'æ˜¯åŸå§‹å›¾åƒçš„æ¯ä¸ªåƒç´ å€¼ï¼Œ'mean'å’Œ'std'åˆ†åˆ«æ˜¯æˆ‘ä»¬æä¾›çš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚è¿™æ ·çš„è½¬æ¢å°†æ•°æ®é›†çš„æ‰€æœ‰ç‰¹å¾ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯åƒç´ ï¼‰ç¼©æ”¾åˆ°å‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º1çš„èŒƒå›´å†…ã€‚\n",
    "\n",
    "è¿™ä¸ªæ“ä½œå¯¹äºè®­ç»ƒæ¨¡å‹éå¸¸é‡è¦ï¼Œå› ä¸ºä¸åŒç‰¹å¾çš„å°ºåº¦å¯èƒ½ä¼šå¯¹ä¼˜åŒ–ç®—æ³•äº§ç”Ÿè´Ÿé¢å½±å“ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ªç‰¹å¾çš„èŒƒå›´åœ¨0åˆ°100ï¼Œè€Œå¦ä¸€ä¸ªç‰¹å¾çš„èŒƒå›´åœ¨0åˆ°1ï¼Œé‚£ä¹ˆå…·æœ‰æ›´å¤§èŒƒå›´çš„ç‰¹å¾å°†å¯¹è®­ç»ƒè¿‡ç¨‹èµ·ä¸»å¯¼ä½œç”¨ï¼Œå› ä¸ºä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚æ¢¯åº¦ä¸‹é™ï¼‰ä¼šå°è¯•å¹³ç­‰åœ°å¤„ç†æ‰€æœ‰ç‰¹å¾ã€‚\n",
    "\n",
    "é€šè¿‡æ ‡å‡†åŒ–æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿æ¯ä¸ªç‰¹å¾åœ¨ä¼˜åŒ–æœŸé—´éƒ½è¢«è€ƒè™‘åˆ°ç›¸åŒç¨‹åº¦ï¼Œä»è€Œä½¿æ¨¡å‹æ›´å®¹æ˜“å­¦ä¹ å¹¶æé«˜å…¶æ€§èƒ½ã€‚è¿™ä¹Ÿæœ‰åŠ©äºåŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        # self.layer1: è¿™æ˜¯ä¸€ä¸ªåŒ…å«å¤šä¸ªå±‚æ¬¡æ“ä½œçš„åºåˆ—ï¼ŒåŒ…æ‹¬å·ç§¯å±‚ï¼ˆConv2dï¼Œè¾“å…¥é€šé“ä¸º1ï¼Œè¾“å‡ºé€šé“ä¸º6ï¼Œä½¿ç”¨5x5çš„å·ç§¯æ ¸ï¼Œæ­¥å¹…ä¸º1ï¼‰ã€\n",
    "        # æ‰¹å½’ä¸€åŒ–å±‚ï¼ˆBatchNorm2dï¼Œå¯¹6ä¸ªé€šé“è¿›è¡Œæ‰¹å¤„ç†å½’ä¸€åŒ–ï¼‰ã€æ¿€æ´»å‡½æ•°ReLUå’Œæœ€å¤§æ± åŒ–å±‚ï¼ˆMaxPool2dï¼Œä½¿ç”¨2x2çš„æ± åŒ–çª—å£ï¼Œæ­¥å¹…ä¸º2ï¼‰ã€‚\n",
    "\n",
    "        # åœ¨æœ¬å±‚ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ± åŒ–æ–¹å¼æ˜¯æœ€å¤§æ± åŒ–æ–¹å¼ã€‚æ± åŒ–çš„å‡ ç§å¸¸è§æ–¹æ³•åŒ…æ‹¬ï¼šå¹³å‡æ± åŒ–ã€æœ€å¤§æ± åŒ–ã€K-maxæ± åŒ–ã€‚\n",
    "        # æœ€å¤§æ± åŒ–ï¼š ä»è¾“å…¥ç‰¹å¾å›¾çš„æŸä¸ªåŒºåŸŸå­å—ä¸­é€‰æ‹©å€¼æœ€å¤§çš„åƒç´ ç‚¹ä½œä¸ºæœ€å¤§æ± åŒ–ç»“æœã€‚\n",
    "        # å¹³å‡æ± åŒ–ï¼š ä»è¾“å…¥ç‰¹å¾å›¾çš„æŸä¸ªåŒºåŸŸå­å—ä¸­é€‰æ‹©å€¼å¹³å‡çš„åƒç´ ç‚¹ä½œä¸ºæœ€å¤§æ± åŒ–ç»“æœã€‚\n",
    "        # K-maxæ± åŒ–ï¼š åœ¨Kä¸ªé€šé“ä¸Šè¿›è¡Œæœ€å¤§æ± åŒ–ï¼Œç„¶åå°†æ¯ä¸ªé€šé“ä¸Šçš„æœ€å¤§æ± åŒ–ç»“æœè¿æ¥èµ·æ¥ä½œä¸ºè¾“å‡ºã€‚\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        # self.layer2: è¿™æ˜¯ç¬¬äºŒä¸ªåŒ…å«å¤šä¸ªå±‚æ¬¡æ“ä½œçš„åºåˆ—ï¼Œç±»ä¼¼äºå‰ä¸€å±‚ä½†æ˜¯è¾“å…¥é€šé“æ•°å˜æˆäº†6ï¼ˆå› ä¸ºä¸Šä¸€å±‚æœ‰6ä¸ªè¾“å‡ºé€šé“ï¼‰ï¼Œè€Œè¾“å‡ºé€šé“æ•°å˜æˆäº†16ã€‚\n",
    "\n",
    "        \n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        # æ¥ä¸‹æ¥å®šä¹‰äº†ä¸‰ä¸ªå…¨è¿æ¥å±‚(self.fc, self.fc1, self.fc2)å’Œä¸¤ä¸ªReLUæ¿€æ´»å‡½æ•°ã€‚\n",
    "        # å…¨è¿æ¥å±‚ç”¨äºå°†å‰ä¸€å±‚çš„è¾“å‡ºæ˜ å°„åˆ°ä¸€ä¸ªç‰¹å®šç»´åº¦çš„ç©ºé—´ï¼Œä»¥ä¾¿è¿›è¡Œåˆ†ç±»æˆ–å›å½’ä»»åŠ¡ã€‚\n",
    "        # è¿™é‡Œï¼Œç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚å°†400ä¸ªç‰¹å¾ï¼ˆç”±å·ç§¯å’Œæ± åŒ–æ“ä½œå¾—æ¥ï¼‰è½¬æ¢ä¸º120ä¸ªç‰¹å¾ï¼Œ\n",
    "        # ç¬¬äºŒä¸ªå°†120ä¸ªç‰¹å¾è½¬æ¢ä¸º84ä¸ªç‰¹å¾ï¼Œæœ€åçš„å…¨è¿æ¥å±‚å°†84ä¸ªç‰¹å¾æ˜ å°„åˆ°æŒ‡å®šæ•°é‡çš„ç±»åˆ«ä¸Šï¼ˆè¿™å°±æ˜¯num_classeså‚æ•°ï¼‰\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    # forwardæ–¹æ³•å®šä¹‰äº†å‰å‘ä¼ æ’­è¿‡ç¨‹ï¼Œå³å¦‚ä½•ä½¿ç”¨è¾“å…¥æ•°æ®æ¥è®¡ç®—æ¨¡å‹çš„é¢„æµ‹ç»“æœã€‚\n",
    "    # å®ƒé¦–å…ˆé€šè¿‡ç¬¬ä¸€å±‚å’Œç¬¬äºŒå±‚å¤„ç†è¾“å…¥æ•°æ®ï¼Œç„¶åå°†è¿™äº›æ•°æ®å±•å¹³æˆä¸€ä¸ªä¸€ç»´å‘é‡ï¼ˆreshapeæ“ä½œï¼‰ï¼Œ\n",
    "    # æ¥ç€é€šè¿‡å…¨è¿æ¥å±‚ã€ReLUæ¿€æ´»å‡½æ•°ä»¥åŠæœ€ç»ˆçš„é¢„æµ‹å±‚è®¡ç®—è¾“å‡ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºäº†ä¸€ä¸ª LeNet5 æ¨¡å‹çš„å®ä¾‹ï¼Œå¹¶å°†å…¶ç§»åŠ¨åˆ°äº†è®¾å¤‡ï¼ˆå¯èƒ½æ˜¯ CPU æˆ– GPUï¼‰ä¸Šã€‚\n",
    "model = LeNet5(num_classes).to(device)\n",
    "\n",
    "# è¿™é‡Œå®šä¹‰äº†æŸå¤±å‡½æ•°ä¸ºäº¤å‰ç†µæŸå¤±ï¼ˆcross-entropy lossï¼‰\n",
    "# äº¤å‰ç†µåˆ»ç”»äº†ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„è·ç¦»ï¼Œæ—¨åœ¨æç»˜é€šè¿‡æ¦‚ç‡åˆ†å¸ƒ ğ‘ æ¥è¡¨è¾¾æ¦‚ç‡åˆ†å¸ƒ ğ‘ çš„å›°éš¾ç¨‹åº¦ã€‚\n",
    "# æ ¹æ®å…¬å¼ä¸éš¾ç†è§£ï¼Œäº¤å‰ç†µè¶Šå°ï¼Œä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒ ğ‘ å’Œ ğ‘ è¶Šæ¥è¿‘ã€‚\n",
    "# å¾ˆæ˜¾ç„¶ï¼Œä¸€ä¸ªè‰¯å¥½çš„ç¥ç»ç½‘ç»œè¦å°½é‡ä¿è¯å¯¹äºæ¯ä¸€ä¸ªè¾“å…¥æ•°æ®ï¼Œ\n",
    "# ç¥ç»ç½‘ç»œæ‰€é¢„æµ‹ç±»åˆ«åˆ†å¸ƒæ¦‚ç‡ä¸å®é™…ç±»åˆ«åˆ†å¸ƒæ¦‚ç‡ä¹‹é—´çš„å·®è·è¶Šå°è¶Šå¥½ï¼Œå³äº¤å‰ç†µè¶Šå°è¶Šå¥½ã€‚\n",
    "# äºæ˜¯ï¼Œå¯å°†äº¤å‰ç†µä½œä¸ºæŸå¤±å‡½æ•°æ¥è®­ç»ƒç¥ç»ç½‘ç»œã€‚\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "# è¿™é‡Œä½¿ç”¨ Adam ä¼˜åŒ–å™¨æ¥æ›´æ–°æ¨¡å‹çš„æƒé‡ã€‚model.parameters() è¿”å›æ¨¡å‹ä¸­æ‰€æœ‰å¯å­¦ä¹ å‚æ•°çš„è¿­ä»£å™¨ï¼Œå¹¶å°†å®ƒä»¬ä¼ é€’ç»™ä¼˜åŒ–å™¨ã€‚\n",
    "# lr=learning_rate æŒ‡å®šäº†å­¦ä¹ ç‡ï¼ˆlearning rateï¼‰ï¼Œå³æ¯æ¬¡æ›´æ–°æƒé‡æ—¶ç§»åŠ¨çš„æ­¥é•¿å¤§å°ã€‚\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# è¿™è¡Œä»£ç è®¡ç®—è®­ç»ƒæ•°æ®åŠ è½½å™¨ä¸­çš„æ ·æœ¬æ•°é‡ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥çŸ¥é“å‰©ä½™çš„æ­¥éª¤æ•°\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [400/938], Loss: 0.0907\n",
      "Epoch [1/10], Step [800/938], Loss: 0.0916\n",
      "Epoch [2/10], Step [400/938], Loss: 0.1063\n",
      "Epoch [2/10], Step [800/938], Loss: 0.0360\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0459\n",
      "Epoch [3/10], Step [800/938], Loss: 0.0269\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0539\n",
      "Epoch [4/10], Step [800/938], Loss: 0.1063\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0020\n",
      "Epoch [5/10], Step [800/938], Loss: 0.0347\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0048\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0082\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0537\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0012\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0043\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0006\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0003\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0004\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0794\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0179\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    # åœ¨å½“å‰æ—¶æœŸå†…ï¼Œå¾ªç¯éå†è®­ç»ƒæ•°æ®åŠ è½½å™¨ä¸­çš„æ¯ä¸ªæ‰¹æ¬¡ï¼ˆå³ä¸€ç»„å›¾åƒå’Œç›¸åº”çš„æ ‡ç­¾ã€‚\n",
    "    # enumerate()å‡½æ•°ç”¨äºè·Ÿè¸ªå½“å‰çš„æ‰¹æ¬¡ç´¢å¼•iã€‚\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #å¯¹æ¨¡å‹ä¼ é€’å½“å‰æ‰¹æ¬¡çš„å›¾åƒå¹¶è·å¾—é¢„æµ‹è¾“å‡ºã€‚\n",
    "        # å‘å‰ä¼ æ’­\n",
    "        outputs = model(images)\n",
    "        loss = cost(outputs, labels)\n",
    "        \t\n",
    "        # æ¸…é™¤ä¼˜åŒ–å™¨ä¸­ç´¯ç§¯çš„æ¢¯åº¦ã€‚åœ¨æ‰§è¡Œåå‘ä¼ æ’­ä¹‹å‰ï¼Œè¿™å¾ˆé‡è¦ï¼Œå› ä¸ºé»˜è®¤æƒ…å†µä¸‹PyTorchä¼šç´¯åŠ æ¢¯åº¦ã€‚\n",
    "        optimizer.zero_grad()\n",
    "        # åå‘ä¼ æ’­\n",
    "        loss.backward()\n",
    "        # ä½¿ç”¨è®¡ç®—å‡ºçš„æ¢¯åº¦æ›´æ–°æ¨¡å‹çš„å‚æ•°ã€‚\n",
    "        optimizer.step()\n",
    "        \n",
    "        # æ¯ 400 æ‰¹æ¬¡æ‰“å°è¾“å‡ºä¸€æ¬¡å½“å‰çš„è¿›åº¦ä¿¡æ¯ã€‚\n",
    "        if (i+1) % 400 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.96 %\n"
     ]
    }
   ],
   "source": [
    "# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚\n",
    "\n",
    "# with torch.no_grad(): - è¿™ä¸€è¡Œè¡¨ç¤ºåœ¨ä»¥ä¸‹ä»£ç å—ä¸­ï¼Œä¸éœ€è¦è®¡ç®—æ¢¯åº¦ã€‚\n",
    "# è¿™æ˜¯å› ä¸ºæµ‹è¯•é˜¶æ®µåªå…³æ³¨æ¨¡å‹çš„æ€§èƒ½ï¼Œè€Œä¸éœ€è¦è¿›è¡Œåå‘ä¼ æ’­å’Œæƒé‡æ›´æ–°ã€‚ \n",
    "with torch.no_grad():\n",
    "\n",
    "    # åˆå§‹åŒ–äº†ç”¨äºè®¡ç®—æ¨¡å‹å‡†ç¡®ç‡çš„å˜é‡ï¼š\n",
    "    # correctè·Ÿè¸ªé¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°ï¼Œ\n",
    "    # è€Œtotalæ˜¯æ•°æ®é›†ä¸­æ€»æ ·æœ¬æ•°ã€‚\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images) # ä½¿ç”¨æµ‹è¯•æ¨¡å‹å¯¹å½“å‰æ‰¹æ¬¡çš„å›¾åƒè¿›è¡Œé¢„æµ‹ã€‚\n",
    "        _, predicted = torch.max(outputs.data, 1) # ä»æ¨¡å‹è¾“å‡ºä¸­è·å–é¢„æµ‹ç±»åˆ«ï¼Œå³å…·æœ‰æœ€é«˜å¾—åˆ†çš„ç±»åˆ«ã€‚\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
